{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando a biblioteca do CNPJ\n",
        "\n"
      ],
      "metadata": {
        "id": "3M8rcIfZNTle"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIekkPttNOpK",
        "outputId": "b48aa0c0-01dc-4aec-81df-7a437fad71df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: basedosdados in /usr/local/lib/python3.10/dist-packages (1.6.11)\n",
            "Requirement already satisfied: Jinja2==3.0.3 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (3.0.3)\n",
            "Requirement already satisfied: ckanapi==4.6 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (4.6)\n",
            "Requirement already satisfied: click==8.0.3 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (8.0.3)\n",
            "Requirement already satisfied: google-cloud-bigquery==2.30.1 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (2.30.1)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage==1.1.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.1.0)\n",
            "Requirement already satisfied: google-cloud-storage==1.42.3 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.42.3)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0,>=4.11.3 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (4.13.0)\n",
            "Requirement already satisfied: loguru<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.6.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.5.3)\n",
            "Requirement already satisfied: pandas-gbq<0.18.0,>=0.17.4 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.17.9)\n",
            "Requirement already satisfied: pandavro<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.8.0)\n",
            "Requirement already satisfied: pyaml==20.4.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (20.4.0)\n",
            "Requirement already satisfied: pyarrow==6.0.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (6.0.0)\n",
            "Requirement already satisfied: ruamel.yaml==0.17.10 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.17.10)\n",
            "Requirement already satisfied: shapely<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.8.5.post1)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.10.2)\n",
            "Requirement already satisfied: tomlkit==0.7.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.7.0)\n",
            "Requirement already satisfied: tqdm==4.50.2 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (4.50.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (71.0.4)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (2.32.3)\n",
            "Requirement already satisfied: python-slugify>=1.0 in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (8.0.4)\n",
            "Requirement already satisfied: six<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (1.64.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=1.29.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.30.1->basedosdados) (1.34.1)\n",
            "Requirement already satisfied: proto-plus>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (1.24.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.7.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.8.2)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage==1.42.3->basedosdados) (2.27.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.0.3->basedosdados) (2.1.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml==20.4.0->basedosdados) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow==6.0.0->basedosdados) (1.26.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<5.0.0,>=4.11.3->basedosdados) (3.20.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->basedosdados) (2024.2)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.3.0)\n",
            "Requirement already satisfied: pydata-google-auth in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.8.2)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.2.1)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pandavro<2.0.0,>=1.6.0->basedosdados) (1.9.7)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=1.29.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.30.1->basedosdados) (1.65.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.30.1->basedosdados) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.0.1->pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==2.30.1->basedosdados) (1.6.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify>=1.0->ckanapi==4.6->basedosdados) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.0.1->pandas-gbq<0.18.0,>=0.17.4->basedosdados) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install basedosdados\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOsJqZTREgOB",
        "outputId": "434e1c14-fec7-4084-d5c6-33c1591c6ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
            "Collecting pyarrow\n",
            "  Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n",
            "Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "Installing collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 6.0.0\n",
            "    Uninstalling pyarrow-6.0.0:\n",
            "      Successfully uninstalled pyarrow-6.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "basedosdados 1.6.11 requires pyarrow==6.0.0, but you have pyarrow 17.0.0 which is incompatible.\n",
            "bigframes 1.17.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.16.0, but you have google-cloud-bigquery 2.30.1 which is incompatible.\n",
            "bigframes 1.17.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.42.3 which is incompatible.\n",
            "bigquery-magics 0.2.0 requires google-cloud-bigquery<4.0.0dev,>=3.13.0, but you have google-cloud-bigquery 2.30.1 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyarrow-17.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando as bibliotecas\n"
      ],
      "metadata": {
        "id": "21ZTdC-5NSk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import graphviz\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "import basedosdados as bd\n"
      ],
      "metadata": {
        "id": "VaStWwLzNVQ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "692819db-da63-4441-ea66-79bd0548cadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'shapely' has no attribute 'strtree'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2aae70a6417a>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbasedosdados\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery_version\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccessEntry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pandas_helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetListItem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetReference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelReference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoutineReference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTableReference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencryption_configuration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncryptionConfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/routine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menums\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeterminismLevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoutine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoutineArgument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/enums.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgapic_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScalarQueryParameterType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/query.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_parse_schema_resource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_rows_from_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_QUERY_PARAMS_FROM_JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mgeopandas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeoseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeoSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeodataframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoints_from_xy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/geoseries.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeoPandasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_delegate_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_explore_geoseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_compat\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeometryArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeometryDtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_from_xy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/array.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHAS_PYPROJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_pyproj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msindex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpatialIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mHAS_PYPROJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/sindex.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeoseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mPREDICATES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshapely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryPredicate\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGEOS_GE_310\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'shapely' has no attribute 'strtree'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pegando a base de dados de alunos do BSI"
      ],
      "metadata": {
        "id": "pgWmxXfSNpQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "H_I6ZU4hN4uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_evasao_desempenho = pd.read_excel(\"/content/gdrive/My Drive/EvasaoBSI.xlsx\")\n"
      ],
      "metadata": {
        "id": "BdlCI3jlODat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_cpf = pd.read_excel(\"/content/gdrive/My Drive/EgressosBaseUnirio.xlsx\"\n"
      ],
      "metadata": {
        "id": "dCsP02olOLiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"Cr_BSI_1\"\n",
        "#file_name = \"CrMat_1\"\n",
        "#file_name = \"CrEngProd_1\"\n",
        "data_cpf = pd.read_excel(\"/content/gdrive/My Drive/dados_mestrado/\"+file_name+\".xlsx\")"
      ],
      "metadata": {
        "id": "sfAKv71JX1ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Substitua na coluna NOME de data_cpf substrings ' por espaço\n",
        "\n",
        "data_cpf['NOME_PESSOA'] = data_cpf['NOME_PESSOA'].str.replace(\"'\", \" \")\n"
      ],
      "metadata": {
        "id": "rFElgW1OY-_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratando o CPF"
      ],
      "metadata": {
        "id": "fL9kZ4ujRZ4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# No valor de data_cpf['CPF_TRATADO'] que tiver 10 caracteres, adicione um 0 na frente.\n",
        "data_cpf['CPF'] = data_cpf['CPF'].astype(str)\n",
        "for i in range(10, 0, -1):\n",
        "    data_cpf['CPF'] = np.where(data_cpf['CPF'].str.len() == i, '0' * (11 - i) + data_cpf['CPF'], data_cpf['CPF'])\n",
        "'''"
      ],
      "metadata": {
        "id": "x_YY-jkYa0kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crie uma nova coluna em data_cpf chamada  CPF_TRATADO, que é formada do seguinte modo: substitua os três primeiros algoritmos por * e substitua os dois últimos algoritmos por * também. Por exemplo: 12345678911 vira ***456789**\n",
        "'''\n",
        "data_cpf['CPF_TRATADO'] = data_cpf['CPF'].astype(str).str.replace(r'(\\d{3})(\\d{3})(\\d{3})(\\d{2})', r'***\\2\\3**')\n",
        "'''"
      ],
      "metadata": {
        "id": "gdPjBUlGReTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_cpf['CPF_TRATADO']"
      ],
      "metadata": {
        "id": "4U-mJPpxaB-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descobrindo os egressos que são donos de empresas"
      ],
      "metadata": {
        "id": "57oMJ1NqPAOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria uma lista com os nomes únicos\n",
        "nomes = data_cpf['NOME_PESSOA'].unique().tolist()\n",
        "cpfs = data_cpf['CPF_TRATADO'].unique().tolist()\n",
        "\n",
        "# Cria uma string para a cláusula WHERE com os nomes\n",
        "nomes_sql = \"', '\".join(nomes)\n",
        "cpfs_sql = \"', '\".join(cpfs )\n",
        "\n",
        "# Cria o cliente BigQuery\n",
        "client = bigquery.Client(project='dissertacao-416315')\n",
        "\n",
        "# Define a consulta com a cláusula WHERE para filtrar pelos nomes\n",
        "query = f\"\"\"\n",
        "SELECT * FROM `basedosdados.br_me_cnpj.socios`\n",
        "WHERE nome IN ('{nomes_sql}') and documento in ('{cpfs_sql}')\n",
        "\"\"\"\n",
        "\n",
        "# Executa a consulta e escreve o resultado em um DataFrame\n",
        "df_socios = pd.read_gbq(query, project_id='dissertacao-416315', reauth=True)"
      ],
      "metadata": {
        "id": "c2WXPwNWPf29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "nomes = data_cpf['NOME_PESSOA'].unique().tolist()\n",
        "cpfs = data_cpf['CPF_TRATADO'].unique().tolist()\n",
        "\n",
        "client = bigquery.Client(project='dissertacao-416315')\n",
        "\n",
        "# Defina a consulta\n",
        "query = \"\"\"\n",
        "SELECT * FROM `basedosdados.br_me_cnpj.Simples` x join `basedosdados.br_me_cnpj.socios` y on (x.cnpj_basico = y.cnpj_basico and  y.nome IN ('{nomes_sql}') and y.documento in ('{cpfs_sql}' ))\n",
        "\"\"\"\n",
        "\n",
        "# Execute a consulta e escreva o resultado em um DataFrame\n",
        "df_meis = pd.read_gbq(query, project_id='dissertacao-416315', reauth=True)\n",
        "'''"
      ],
      "metadata": {
        "id": "5Iek6FknX0Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Crie uma nova coluna em df_socios chamada 'mei' onde houver intersecção de 'nome' de df_socios com 'nome' com df_meis\n",
        "'''\n",
        "df_socios['mei'] = df_socios['nome'].isin(df_meis['nome']).astype(int)\n",
        "df_socios\n",
        "'''"
      ],
      "metadata": {
        "id": "cCnOypXQUNFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Pegue valores únicos de df_socios pelo nome\n",
        "\n",
        "df_socios_unicos = df_socios.drop_duplicates(subset='nome')\n",
        "#df_socios_unicos"
      ],
      "metadata": {
        "id": "ohTD45tFioyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Crie uma nova coluna em data_cpf chamada \"Empresario\". Preencha essa coluna com 1 caso data_cpf.NOME = df_socios_unicos.nome e data_cpf.CPF_TRATADO = df_socios_unicos.documento, caso o contrário, preencha com 0.\n",
        "\n",
        "data_cpf['Empresario'] = np.where((data_cpf['NOME_PESSOA'].isin(df_socios_unicos['nome'])) & (data_cpf['CPF_TRATADO'].isin(df_socios_unicos['documento'])), 1, 0)\n"
      ],
      "metadata": {
        "id": "g6eoPW6z7pOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_cpf"
      ],
      "metadata": {
        "id": "nny4mwwv8lxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Liste os valores das colunas de data_cpf cujo Empresario = 1.\n",
        "\n",
        "#data_cpf[data_cpf['Empresario'] == 1]\n"
      ],
      "metadata": {
        "id": "raOBYdi-91Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Liste os valores das colunas de data_cpf cujo Empresario = 1 e CURSO = \"Sistemas de Informação - Bacharelado - Turno Integral (V/N)\"\n",
        "\n",
        "#data_cpf[(data_cpf['Empresario'] == 1) & (data_cpf['NOME_CURSO'] == \"Sistemas de Informação - Bacharelado - Turno Integral (V/N)\")]\n"
      ],
      "metadata": {
        "id": "LfOlonU7FQWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Faça um histograma dos 10 CURSO que tem mais empresários = 1\n",
        "\n",
        "data_cpf.groupby('NOME_CURSO')['Empresario'].sum().nlargest(10).plot(kind='bar')\n"
      ],
      "metadata": {
        "id": "_V8foseX-GUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabalhando com as datas de evasão e entrada na sociedade"
      ],
      "metadata": {
        "id": "i9PR_V4S9wb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_cpf['DT_EVASAO']"
      ],
      "metadata": {
        "id": "c027wxi3Cn_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Junte df_socios com data_cpf onde df_socios.nome = data_cpf.NOME e df_socios.documento =  data_cpf.CPF_TRATADO\n",
        "\n",
        "df_merged = pd.merge(df_socios_unicos, data_cpf, left_on=['nome', 'documento'], right_on=['NOME_PESSOA', 'CPF_TRATADO'])\n"
      ],
      "metadata": {
        "id": "LfiKQlgUCuQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged"
      ],
      "metadata": {
        "id": "olaXSAg1DP1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged['data_entrada_sociedade']"
      ],
      "metadata": {
        "id": "8FmVkxyjYtDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged['DT_EVASAO']"
      ],
      "metadata": {
        "id": "UG6pwnzvZOV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Converta df_merged['data_entrada_sociedade'] para datetime64[ns]\n",
        "\n",
        "df_merged['data_entrada_sociedade'] = pd.to_datetime(df_merged['data_entrada_sociedade'], errors='coerce', format='%Y-%m-%d')\n",
        "df_merged['DT_EVASAO'] = pd.to_datetime(df_merged['DT_EVASAO'], errors='coerce', format='%Y-%m-%d')\n",
        "df_merged['year4'] = pd.to_datetime(df_merged['year4'], errors='coerce', format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "ukcR4YjKGkuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_merged['DT_EVASAO']"
      ],
      "metadata": {
        "id": "15JWp3mHSzVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_merged['data_entrada_sociedade']"
      ],
      "metadata": {
        "id": "q6JMBph9Yhp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Crie uma nova coluna em df_merged chamada Tempo_Evasao_Sociedade, que é a diferença de tempo entre DT_EVASAO e data_entrada_sociedade\n",
        "\n",
        "df_merged['Tempo_Evasao_Sociedade'] = df_merged['DT_EVASAO'] - df_merged['data_entrada_sociedade']\n",
        "df_merged['Tempo_Evasao_Sociedade']"
      ],
      "metadata": {
        "id": "cV2U9AOBDb9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_merged['Tempo_Evasao_Sociedade'] = df_merged['year4'] - df_merged['data_entrada_sociedade']\n",
        "#df_merged['Tempo_Evasao_Sociedade']"
      ],
      "metadata": {
        "id": "d0KJsN1lFDon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Converta df_merged['ANO_INGRESSO'] ] para DatetimeArray\n",
        "\n",
        "df_merged['ANO_INGRESSO'] = pd.to_datetime(df_merged['ANO_INGRESSO'], format='%Y')\n"
      ],
      "metadata": {
        "id": "1T39Ycv6y6KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged['Tempo_Universidade_Sociedade'] = df_merged['ANO_INGRESSO']  - df_merged['data_entrada_sociedade']\n",
        "df_merged['Tempo_Universidade_Sociedade']"
      ],
      "metadata": {
        "id": "5l3N3Lt-x5jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Faça um gráfico de barras de df_merged['Tempo_Evasao_Sociedade'] para duas categoria: valores menores que 0 e valores maiores que 0.\n",
        "\n",
        "df_merged['Tempo_Evasao_Sociedade_Cat'] = np.where(df_merged['Tempo_Evasao_Sociedade'] < pd.Timedelta(0), 'Fundou uma empresa depois da graduação' ,'Fundou uma empresa antes da graduação')\n",
        "\n",
        "df_merged.groupby('Tempo_Evasao_Sociedade_Cat')['Tempo_Evasao_Sociedade'].count().plot(kind='bar')\n"
      ],
      "metadata": {
        "id": "LkSxc-9tG6U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged['Tempo_Universidade_Sociedade_Cat'] = np.where(df_merged['Tempo_Universidade_Sociedade'] < pd.Timedelta(0),'Fundou uma empresa depois de entrar na faculdade' , 'Fundou uma empresa antes de entrar na faculdade')\n",
        "\n",
        "df_merged.groupby('Tempo_Universidade_Sociedade_Cat')['Tempo_Universidade_Sociedade'].count().plot(kind='bar')"
      ],
      "metadata": {
        "id": "N_DB5dDXzPwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Coloque a tabela df_merged['Tempo_Evasao_Sociedade_Cat'] em data_cpf onde df_socios.nome = data_cpf.NOME e df_socios.documento =  data_cpf.CPF_TRATADO\n",
        "\n",
        "data_cpf = data_cpf.merge(df_merged[['Tempo_Evasao_Sociedade_Cat']], left_on=['NOME_PESSOA', 'CPF_TRATADO'], right_on=[df_merged['nome'],df_merged['documento'] ], how='left')\n",
        "data_cpf['Tempo_Evasao_Sociedade_Cat'].fillna('Não é empresário', inplace=True)\n",
        "# data_cpf"
      ],
      "metadata": {
        "id": "DvkEwHewIhDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cpf = data_cpf.merge(df_merged[['Tempo_Universidade_Sociedade_Cat']], left_on=['NOME_PESSOA', 'CPF_TRATADO'], right_on=[df_merged['nome'],df_merged['documento'] ], how='left')\n",
        "data_cpf['Tempo_Universidade_Sociedade_Cat'].fillna('Não é empresário', inplace=True)"
      ],
      "metadata": {
        "id": "8HMcySdf0aPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consolidação para o modelo"
      ],
      "metadata": {
        "id": "2duykWHObgqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_cpf"
      ],
      "metadata": {
        "id": "AbVOESVDbbbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_cpf.to_excel(\"/content/gdrive/My Drive/dados_mestrado/data_cpf_modelo.xlsx\")"
      ],
      "metadata": {
        "id": "-cOFHMd0bvX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_cpf[data_cpf['Empresario'] == 1]\n"
      ],
      "metadata": {
        "id": "acy3iMchLh7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def definir_categoria(row):\n",
        "    if row['Tempo_Evasao_Sociedade_Cat'] == 'Não é empresário' and row['Tempo_Universidade_Sociedade_Cat'] == 'Não é empresário':\n",
        "        return 'Não é empresário'\n",
        "    elif row['Tempo_Evasao_Sociedade_Cat'] == 'Fundou uma empresa antes da graduação' and row['Tempo_Universidade_Sociedade_Cat'] == 'Fundou uma empresa depois de entrar na faculdade':\n",
        "        return 'Fundou uma empresa durante a graduação'\n",
        "    elif row['Tempo_Evasao_Sociedade_Cat'] == 'Fundou uma empresa depois da graduação':\n",
        "        return 'Fundou uma empresa depois da graduação'\n",
        "    elif row['Tempo_Universidade_Sociedade_Cat'] == 'Fundou uma empresa antes de entrar na faculdade':\n",
        "        return 'Fundou uma empresa antes de entrar na graduação'\n",
        "    else:\n",
        "        return 'Categoria Não Definida'  # Para qualquer caso que não se encaixe nas condições acima\n",
        "\n",
        "\n",
        "# Aplicar a função para criar a nova coluna\n",
        "data_cpf['Categoria'] = data_cpf.apply(definir_categoria, axis=1)\n"
      ],
      "metadata": {
        "id": "_gmoIeCSM3Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Faça de um gráfico de barras de Tempo_Evasao_Sociedade_Cat de data_cpf\n",
        "data_cpf_unicos = data_cpf.drop_duplicates(subset='NOME_PESSOA')\n",
        "\n",
        "data_cpf_unicos['Categoria'].value_counts().plot(kind='bar')\n"
      ],
      "metadata": {
        "id": "gZvx77gKiQBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cpf_unicos[data_cpf_unicos['Empresario'] == 1]"
      ],
      "metadata": {
        "id": "JmuG7xcwa915"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iguais = data_cpf[data_cpf['ANO'] == data_cpf['ANO_INGRESSO']]\n",
        "data_unicos = data_iguais.drop_duplicates(subset='NOME_PESSOA')\n",
        "\n",
        "\n",
        "file_name = file_name+\"_2.xlsx\"\n",
        "data_cpf_unicos.to_excel(\"/content/gdrive/My Drive/dados_mestrado/\"+file_name)"
      ],
      "metadata": {
        "id": "bABEwz26PU49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = file_name+\"_2.xlsx\"\n",
        "data_cpf_unicos.to_csv(\"/content/gdrive/My Drive/dados_mestrado/\"+file_name)"
      ],
      "metadata": {
        "id": "4nyblgq8rqXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Reduce the number of columns by dropping unnecessary columns\n",
        "#data_cpf_reduced = data_cpf.drop(columns=['Tempo_Evasao_Sociedade_Cat', 'Tempo_Universidade_Sociedade_Cat', 'NOME_CURSO', 'CPF_TRATADO', 'NOME_PESSOA', 'DT_EVASAO', 'FORMA_EVASAO'])\n",
        "\n",
        "# Save the reduced DataFrame to Excel\n",
        "#data_cpf_reduced.to_excel(\"/content/gdrive/My Drive/dados_mestrado/data_cpf_modelo_bsi_notas.xlsx\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pxSLk5tO_hGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eOxev6CuezHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "data_bsi = data_cpf[(data_cpf['Empresario'] == 1) & (data_cpf['NOME_CURSO'] == \"Sistemas de Informação - Bacharelado - Turno Integral (V/N)\")]\n",
        "\n",
        "# Cria uma lista com os nomes únicos\n",
        "nomes_bsi = data_bsi['NOME_PESSOA'].unique().tolist()\n",
        "cpfs_bsi = data_bsi['CPF_TRATADO'].unique().tolist()\n",
        "\n",
        "# Cria uma string para a cláusula WHERE com os nomes\n",
        "nomes_sql_bsi = \"', '\".join(nomes_bsi)\n",
        "cpfs_sql_bsi = \"', '\".join(cpfs_bsi)\n",
        "\n",
        "# Crie um cliente BigQuery\n",
        "client = bigquery.Client(project='dissertacao-416315')\n",
        "\n",
        "# Defina a consulta\n",
        "query = f\"\"\"\n",
        "SELECT * FROM `basedosdados.br_me_cnpj.empresas` x\n",
        "join `basedosdados.br_me_cnpj.socios` y on (x.cnpj_basico = y.cnpj_basico\n",
        "and y.nome in ('{nomes_sql_bsi}') and documento in ('{cpfs_sql_bsi}')) LIMIT 1000\n",
        "\"\"\"\n",
        "# Execute a consulta e escreva o resultado em um DataFrame\n",
        "df_donos_bsi = pd.read_gbq(query, project_id='dissertacao-416315', reauth=True)\n",
        "'''"
      ],
      "metadata": {
        "id": "8pLzgR3TKP-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_donos_bsi = df_donos_bsi.drop_duplicates(subset='nome')\n",
        "# df_donos_bsi"
      ],
      "metadata": {
        "id": "HGCjYZehNnQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Crie um dataset chamado de empresarios_bsi juntado df_donos_bsi.nome com data_cpf.NOME  e df_donos_bsi.documento com data_cpf.CPF_TRATADO. Pegue as somente essas colunas e df_donos_bsi.razao_social e data_cpf.Tempo_Evasao_Sociedade_Cat\n",
        "\n",
        "# empresarios_bsi = pd.merge(df_donos_bsi[['nome', 'documento', 'razao_social']], data_cpf[['NOME_PESSOA', 'CPF_TRATADO', 'Tempo_Evasao_Sociedade_Cat']], left_on=['nome', 'documento'], right_on=['NOME_PESSOA', 'CPF_TRATADO'])[['nome', 'documento', 'razao_social', 'Tempo_Evasao_Sociedade_Cat']]\n",
        "# empresarios_bsi"
      ],
      "metadata": {
        "id": "MfAS-G9JPo7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Pegue empresarios_bsi por nome único\n",
        "\n",
        "# empresarios_bsi_unicos = empresarios_bsi.drop_duplicates(subset='nome')\n",
        "# empresarios_bsi_unicos"
      ],
      "metadata": {
        "id": "9C6zcbDZaMNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo para prever desempenho acadêmico"
      ],
      "metadata": {
        "id": "LxM1yqoPkzgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_modelo = data_cpf[['ingresso_atual', 'MEDIA_FINAL', 'CR_ATUAL', 'CR_NO_PERIODO', 'Empresario', 'Categoria']]\n"
      ],
      "metadata": {
        "id": "4lXUVImgfKnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformar as colunas de data modelo que são categóricas, como ingresso_atual, FORMA_EVASAO e Tempo_Evasao_Sociedade_Cat, em colunas numéricas\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Apply the label encoder to the categorical columns\n",
        "data_modelo['ingresso_atual'] = le.fit_transform(data_modelo['ingresso_atual'])\n",
        "data_modelo['Categoria'] = le.fit_transform(data_modelo['Categoria'])"
      ],
      "metadata": {
        "id": "oQf5fkMJf994"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = smote.fit_resample(data_modelo.drop(\"Empresario\", axis=1), data_modelo[\"Empresario\"])\n",
        "\n",
        "data_resampled = pd.concat([pd.DataFrame(X_resampled, columns=data_modelo.drop(\"Empresario\", axis=1).columns), pd.DataFrame(y_resampled, columns=[\"Empresario\"])], axis=1)\n",
        "\n",
        "data_resampled.groupby(\"Empresario\").size().plot(kind=\"bar\")"
      ],
      "metadata": {
        "id": "-jeRmjttgFly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Define the dependent and independent variables\n",
        "dependent_variable = data_modelo[\"CR_ATUAL\"]\n",
        "independent_vars = data_modelo[[\"ingresso_atual\", \"MEDIA_FINAL\", \"CR_NO_PERIODO\", \"Empresario\", \"Categoria\"]]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "7zA9azO_gFmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(independent_vars, dependent_variable)\n",
        "\n",
        "# Coeficientes da regressão linear\n",
        "coefficients = model.coef_\n",
        "\n",
        "# Calcular o valor agregado das variáveis independentes\n",
        "aggregated_value = np.dot(independent_vars, coefficients)\n",
        "\n",
        "# Prever os valores da variável dependente usando o modelo ajustado\n",
        "predicted_values = model.predict(independent_vars)\n",
        "\n",
        "# Criar o scatterplot\n",
        "plt.scatter(aggregated_value, dependent_variable, label='Real Data')\n",
        "\n",
        "# Plotar a linha de regressão\n",
        "# Note que usamos `aggregated_value` para criar a linha, mas poderíamos também usar as variáveis independentes diretamente\n",
        "plt.plot(aggregated_value, predicted_values, color='red', label='Regression Line')\n",
        "\n",
        "# Adicionar rótulos e título\n",
        "plt.xlabel('Independent features: Agregated Value of admission method, final grade on each discipline, semester GPA, IsTheyBusinessperson, Category of businessperson student')\n",
        "plt.ylabel('Dependent feature: Accumulated GPA')\n",
        "plt.title('Scatter Plot of Dependent Variable and Added Value of Independent Variables with Regression Line')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar o gráfico\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "AEA-PmpvmB4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "r_squared = model.score(independent_vars, dependent_variable)\n",
        "print(f'R^2 value: {r_squared}')\n",
        "'''"
      ],
      "metadata": {
        "id": "1SKycKt2mU0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(model, independent_vars, dependent_variable, cv=5, scoring='r2')\n",
        "print(f'Scores de validação cruzada: {cv_scores}')\n",
        "print(f'Média dos scores de validação cruzada: {cv_scores.mean()}')\n",
        "'''"
      ],
      "metadata": {
        "id": "Q1sge1Ajr4pp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}